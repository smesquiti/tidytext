---
title: "Network Analysis for Tokens"
author: "Steven Mesquiti"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    df_print: paged
    highlight: tango
    theme: united
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  word_document:
    toc: yes
  pdf_document:
    toc: yes
---
# Markdown to visualize topic model!
```{r setup, include=FALSE}
# set chunk options for the document
# include=FALSE means that this chunk will not show up in the report
knitr::opts_chunk$set(echo = TRUE, dpi = 150, fig.path = "figs/") 
# echo = TRUE means that the source code will be displayed
# dpi = 150 sets the figure resolution
# fig.path specifies a directory where figures will be output
options(scipen = 999) #turn off scientific notation
set.seed(65) #set seed for random number generation
```

This is a markdown file that demonstrates how to do a network analysis of tokenized text to complement Meaning Extraction Helper.


# Prep {.tabset}
## Load packages
The **job** package is a great package to use for running things with long wait times. You can read more about [job here](https://lindeloev.github.io/job/) if you choose to run it as a script.
```{r, message=FALSE}
if (!require(pacman)) {
  install.packages('pacman')
}
pacman::p_load(tidyverse, tidytext, igraph, ggraph, widyr, job, devtools, install = T)
devtools::install_github("hadley/emo")
```

## Load data and prep the data. Note if you are working with other data this **will** change!
```{r}
setwd("~/Desktop/CEO Project") #set WD to where our files live 

data  <- read.csv(file = "Big_CEO.csv", stringsAsFactors = FALSE)


data <- data["2019-03-01"<= data$Date & data$Date <= "2021-04-01",] #subsetting covid dates 
data <- data %>% filter(WC<=5400) %>% #filter out based on our exclusion criteria
  filter(WC>=25)

df <- data[, c(1:9)] #we trimmed it down to include stuff we want
```

## Tokenize the Data... which will take awhile.
```{r}
df_bigrams <- df %>% 
  unnest_tokens(bigram, aggregated_text, token = 'ngrams', n = 2) %>% 
  filter(!is.na(bigram))
```



# Starting Network analysis {.tabset}
For this tutorial, we are using the CEO dataset, which is kinda large so note that we trim some stuff and rely on background jobs to speed this up.


## Separate the Data 
```{r}
bigrams_separated <- df_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

```

## Take out the stop words. Please note, this is the preloaded stop word list, which can be customized. 
```{r}
  bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

```

## Counting bigrams and taking *only* high frequency ones :). Please adjust the N to fit your dataset
```{r}
# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

# filter for only relatively common combinations. bigger is better here
bigram_graph <- bigram_counts %>%
  filter(n > 400) %>%
  graph_from_data_frame()
```

# build your network graph
```{r}
#start building
#more refinedgraph
#start building
set.seed(2020)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```




# Resources
## Reproducible reports in R
* [Improve your workflow for reproducible science - Mine Ã‡etinkaya-Rundel](https://mine-cr.com/talk/2021-improve-workflow-repro-science-oss/)
* [R Markdown for writing reproducible scientific papers - Mike Frank & Chris Hartgerink](https://libscie.github.io/rmarkdown-workshop/handout.html)
* [R Markdown for scientists - Nicholas Tierney](https://rmd4sci.njtierney.com/)
* [Reproducible Analysis with R](https://nceas.github.io/sasap-training/materials/reproducible_research_in_r_fairbanks/)
* [Reproducible science curriculum](https://github.com/Reproducible-Science-Curriculum)

## R Markdown
* [R Markdown](https://rmarkdown.rstudio.com/lesson-1.html)
* [R Markdown reference guide](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf?_ga=2.245086913.571798724.1647284447-1046469491.1644870105)

## Themes
* [R Markdown theme gallery](https://www.datadreaming.org/post/r-markdown-theme-gallery/)
* [{rmdformats} theme package](https://juba.github.io/rmdformats/)
